# Image Captioning using pre-trained GPT-2 models

**Author:** Javier Garc√≠a Gilabert

**Tutor:** Francisco Casacuberta Nolla

The objective of image captioning is to describe the content of an image in natural language. Due to the success of various deep learning architectures, this challenge that combines picture and language processing has aroused a lot of attention in recent years. The key goal for this end grade project is to create more accurate neural machine models for image captioning.

Several neural network-based models are built based on the CLIP neural network, which offers similar embeddings given an image and a descriptive caption. This, in conjunction with GPT-2, a language model, is used to propose various deep learning designs. The MSCOCO dataset, which consists of complex everyday scenes with natural language descriptions, will be used to compare different architectures.
